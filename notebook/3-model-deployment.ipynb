{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe16d20",
   "metadata": {},
   "source": [
    "# Phase 3: Model Deployment \n",
    "\n",
    "In the final phase of the assignment, we focus on deploying the optimized model using Google Cloud's Vertex AI. This phase leverages the `gcloud` command-line interface (CLI) for deploying and managing machine learning models on the cloud platform.\n",
    "\n",
    "## Rationale for Using gcloud CLI\n",
    "\n",
    "Vertex AI offers various interfaces for interaction, including the UI (Cloud Console), the `gcloud` CLI, and SDKs for languages such as Python and Java. While the UI is convenient for exploratory and manual tasks, it is less suited for production environments due to its less programmable nature. On the other hand, SDKs provide deep integration within codebases but require adjustments whenever deployment specifications change. \n",
    "\n",
    "The `gcloud` CLI strikes a perfect balance by offering several advantages for production-grade deployments:\n",
    "1. **Scriptability and Automation**: The CLI allows for scripting complex operations which can be automated without manual intervention. This is crucial for production environments where deployments need to be reproducible and consistent.\n",
    "2. **Parameterization**: CLI commands can be parameterized easily within scripts. This allows for changing deployment parameters such as model names, instance types, regions, and other configurations without altering the core logic of the deployment scripts.\n",
    "3. **Flexibility**: It provides the flexibility needed in dynamic production environments. Changes can be rolled out quickly by adjusting the parameters in the CLI commands.\n",
    "4. **No Code-Level Changes Required**: Using the CLI reduces the need for frequent code changes. Deployment scenarios can be handled by script adjustments, minimizing the potential for bugs and reducing development overhead.\n",
    "\n",
    "## Deployment Strategy Using gcloud CLI\n",
    "\n",
    "The deployment process is streamlined into a sequence of `gcloud` commands that handle tasks such as:\n",
    "- Uploading the model to Vertex AI.\n",
    "- Creating an endpoint for the model.\n",
    "- Deploying the model to the endpoint with specific machine types and scaling configurations.\n",
    "\n",
    "Each of these steps can be executed via a single command, with parameters controlled through command-line arguments or environment variables, ensuring that the process is both flexible and easily repeatable.\n",
    "\n",
    "By utilizing the `gcloud` CLI for deploying models on Vertex AI, we achieve a high degree of automation and flexibility, crucial for scaling machine learning operations in production environments. This approach helps maintain a clear separation between deployment logistics and model development, leading to more robust and maintainable workflows.\n",
    "\n",
    "In summary, the `gcloud` CLI is an effective tool for managing Vertex AI operations, advisable for scenarios demanding regular updates or deployments without the need for direct code manipulation, suitable for continuous integration/continuous deployment (CI/CD) pipelines.\n",
    "\n",
    "After completing the hyperparameter tuning phase and identifying the best performing model based on the AUC-PR metric, we must prepare the model for deployment on Vertex AI. Vertex AI requires models to be in a specific format (.bst for XGBoost) for optimal compatibility with its managed services. Thus, converting our model from JSON to BST format becomes necessary before proceeding to model registration and deployment.\n",
    "\n",
    "### Step 1: Model Format Conversion\n",
    "\n",
    "The model trained and saved in JSON format needs to be converted to the BST format, which is the native binary format used by XGBoost, and is preferred for deployment on Vertex AI due to its efficiency in load times and compatibility. The conversion involves renaming the model file from `.json` to `.bst`. This is done using the `gsutil mv` command, which moves and renames the model file within Google Cloud Storage. Here's how this is accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e188bee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Google Cloud CLI components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "Copying gs://telco-churn-prediction/model/xgboost_model17128808474388263.json [Content-Type=application/json]...\n",
      "Removing gs://telco-churn-prediction/model/xgboost_model17128808474388263.json...\n",
      "\n",
      "Operation completed over 1 objects/341.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil mv gs://telco-churn-prediction/model/xgboost_model17128808474388263.json \\\n",
    "    gs://telco-churn-prediction/model/model.bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf61b45",
   "metadata": {},
   "source": [
    "This command effectively renames 'xgboost_model17128808474388263.json' to 'model.bst', preparing it for deployment.\n",
    "\n",
    "### Step 2: Uploading the Model to Vertex AI\n",
    "\n",
    "Once the model is in the correct format, the next step is to register it with Vertex AI's Model Registry. This allows the model to be managed, versioned, and deployed systematically. The model is uploaded using the `gcloud ai models upload` command, which specifies necessary parameters such as the region, display name, the container image for running the model, and the location of the model artifacts. Here is the command used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c1e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7564476171866341376]...done.                            \n"
     ]
    }
   ],
   "source": [
    "!gcloud ai models upload \\\n",
    "  --region=asia-south1 \\\n",
    "  --display-name=churn-prediction-xgboost-best-model \\\n",
    "  --container-image-uri=asia-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest \\\n",
    "  --artifact-uri=gs://telco-churn-prediction/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405852e",
   "metadata": {},
   "source": [
    "#### Key Parameters Explained:\n",
    "- **--region**: Specifies the Google Cloud region where the model will be hosted. This should match the region where the endpoints will be deployed.\n",
    "- **--display-name**: A user-friendly name for the model in the Vertex AI dashboard.\n",
    "- **--container-image-uri**: This parameter points to a container image that is used to serve the model. For XGBoost models, Vertex AI offers optimized container images.\n",
    "- **--artifact-uri**: The URI where the model's artifacts are stored. It should point to the directory containing the `.bst` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae4f48",
   "metadata": {},
   "source": [
    "### Step 3: Model Listing\n",
    "To start the deployment process, begin by listing all the models available in the specified region under your Google Cloud project. This provides a comprehensive view of all models, including their unique identifiers and display names. Listing the models is crucial to ensure accurate model selection for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5492fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "MODEL_ID                                          DISPLAY_NAME\n",
      "3839608953403080704                               churn-prediction-xgboost-best-model\n",
      "5122404771482828800                               xgboost-best-model-hpo-1-v2\n",
      "7821257216928776192                               universal_model_low_features\n",
      "mistralai_mistral-7b-instruct-v0_1-1704100088152  mistralai_mistral-7b-instruct-v0_1-1704100088152\n",
      "4554458637224902656                               utech-universal-model\n",
      "5520058544830808064                               current_phase_c\n",
      "192300185651511296                                current_phase_b\n",
      "4803986204078899200                               current_phase_a\n",
      "3214215535617114112                               total_active_energy\n",
      "7825901554044502016                               total_active_power\n",
      "2061294031010267136                               voltage_a_n\n",
      "6672980049437655040                               voltage_b_n\n",
      "25666999438802944                                 voltage_c_n\n",
      "4750505958503874560                               active_power_forecast\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai models list --region=asia-south1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aee609",
   "metadata": {},
   "source": [
    "### Step 4: Endpoint Creation\n",
    "Create a new endpoint in Vertex AI to serve predictions. An endpoint acts as a consolidated gateway through which different versions of your models can be accessed. The creation of endpoints is pivotal as it defines the environment and attributes such as the region, which plays a vital role in latency and accessibility for prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a794833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [8220875817555591168]...done.                            \n",
      "Created Vertex AI endpoint: projects/777232604101/locations/asia-south1/endpoints/3538624242369167360.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints create \\\n",
    "  --region=asia-south1 \\\n",
    "  --display-name=churn-prediction-xgboost-best-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67596be9",
   "metadata": {},
   "source": [
    "### Step 5: Listing Endpoints\n",
    "After creating the endpoint, list the available endpoints in the region to confirm the successful creation and to check for details such as endpoint IDs, which are necessary for deploying models to these endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e027f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "ENDPOINT_ID          DISPLAY_NAME\n",
      "3538624242369167360  churn-prediction-xgboost-best-model\n",
      "5844150592234061824  2024-01-01-utech-energy\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints list --region=asia-south1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536729f",
   "metadata": {},
   "source": [
    "### Step 6: Model Deployment to Endpoint\n",
    "Deploy the specific model to the recently created endpoint. This process includes specifying the model by its ID, defining display names for organizational clarity, and setting operational parameters such as the number of replicas. These configurations are essential for handling load and ensuring reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea7a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7288630694689898496]...done.                            \n",
      "Deployed a model to the endpoint 3538624242369167360. Id of the deployed model: 3579789957713100800.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints deploy-model 3538624242369167360 \\\n",
    "  --region=asia-south1  \\\n",
    "  --model=3839608953403080704 \\\n",
    "  --display-name=churn-prediction-xgboost \\\n",
    "  --min-replica-count=1 \\\n",
    "  --max-replica-count=2 \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691e914",
   "metadata": {},
   "source": [
    "### Step 7: Endpoint Configuration and Traffic Management\n",
    "Post-deployment, confirm the configuration by describing the endpoint. This description should include detailed configurations like the number of replicas, the machine type used, and other deployment-specific details. It should also show the traffic split, which is primarily used to manage multiple model versions under the same endpoint, directing a percentage of incoming traffic to different model variants.\n",
    "\n",
    "Each of these steps plays a crucial role in the deployment lifecycle within Vertex AI, designed to streamline and simplify the process of getting models from training to serving. This approach ensures that the models are not only deployed efficiently but are also scalable and manageable in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396a905c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-aiplatform.googleapis.com/]\n",
      "createTime: '2024-04-12T11:09:27.874162Z'\n",
      "deployedModels:\n",
      "- createTime: '2024-04-12T11:36:33.249975Z'\n",
      "  dedicatedResources:\n",
      "    machineSpec:\n",
      "      machineType: n1-standard-2\n",
      "    maxReplicaCount: 2\n",
      "    minReplicaCount: 1\n",
      "  displayName: churn-prediction-xgboost\n",
      "  id: '3579789957713100800'\n",
      "  model: projects/777232604101/locations/asia-south1/models/3839608953403080704\n",
      "  modelVersionId: '1'\n",
      "displayName: churn-prediction-xgboost-best-model\n",
      "etag: AMEw9yO7Wku4sD8JyUEwG9T9CSGH8wspStZe6UJx26oGuPo-81i-AlBcm8J0bJANQT2q\n",
      "name: projects/777232604101/locations/asia-south1/endpoints/3538624242369167360\n",
      "trafficSplit:\n",
      "  '3579789957713100800': 100\n",
      "updateTime: '2024-04-12T11:46:16.994965Z'\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints describe 3538624242369167360 --region=asia-south1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98878f",
   "metadata": {},
   "source": [
    "## Process for Making Real-Time Predictions\n",
    "\n",
    "The process outlined for making real-time predictions leverages the capabilities of Google Cloud’s Vertex AI to deploy a machine learning model that forecasts customer churn. The predictions are derived from a preprocessed dataset, where data transformation and feature engineering are critical components ensuring data compatibility with the model’s input requirements.\n",
    "\n",
    "### Data Preparation and Preprocessing\n",
    "- **Data Loading and Initial Processing:** The dataset is loaded into a pandas DataFrame. Key transformations include converting 'TotalCharges' from a string to numeric and handling missing values.\n",
    "- **Feature Engineering:** New features are derived, such as 'AverageMonthlyCharges', and 'tenure' is categorized into groups. These steps are aimed at enriching the model's input to capture more complex patterns.\n",
    "- **Encoding and Scaling:** Categorical variables are encoded using both label encoding and one-hot encoding to transform them into a machine-readable format. Numerical features are scaled to ensure model sensitivity is uniform across variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2ed090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c13c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/telco_customer_churn_data.csv')\n",
    "df_original = df.copy()\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "# Create 'AverageMonthlyCharges' by dividing 'TotalCharges' by 'tenure'\n",
    "# Handle cases where tenure is zero: AverageMonthlyCharges should be the same as MonthlyCharges\n",
    "df['AverageMonthlyCharges'] = np.where(df['tenure'] != 0, df['TotalCharges'] / df['tenure'], df['MonthlyCharges'])\n",
    "\n",
    "# Categorize 'tenure' into different groups\n",
    "df['TenureGroups'] = pd.cut(df['tenure'], bins=[0, 12, 24, 48, 60, np.inf], labels=['0-1 year', '1-2 years', '2-4 years', '4-5 years', '5+ years'])\n",
    "\n",
    "# List of binary categorical columns to encode as 0 and 1\n",
    "binary_columns = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\", \"Churn\"]\n",
    "\n",
    "# Encode binary categorical variables using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in binary_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# List of nominal columns to apply one-hot encoding\n",
    "nominal_columns = [\n",
    "    \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\",\n",
    "    \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "    \"Contract\", \"PaymentMethod\", \"TenureGroups\"\n",
    "]\n",
    "\n",
    "# Apply one-hot encoding using get_dummies in pandas\n",
    "df = pd.get_dummies(df, columns=nominal_columns, drop_first=False, dtype=int)\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = [\"AverageMonthlyCharges\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "\n",
    "# Initialize MinMaxScaler to scale numerical columns to be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaler separately for each column\n",
    "for col in numerical_columns:\n",
    "    df[col] = df[col].astype(float)  # Ensure data type is float for scaling\n",
    "    df[col] = scaler.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc47b08",
   "metadata": {},
   "source": [
    "### Serialization and Prediction\n",
    "- **Data Serialization:** A subset of the dataset intended for demonstration purposes is selected and serialized into JSON format. This serialized data represents the model input for making predictions.\n",
    "- **Invoking the Prediction:** The serialized input is fed to a model hosted on a Vertex AI endpoint using the `gcloud ai endpoints predict` command. This setup helps in making real-time predictions by providing an automated way to query the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bf5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset for demonstration (e.g., 100 rows)\n",
    "demo_df = df.sample(n=10, random_state=42)\n",
    "\n",
    "# Keep customerID for later reference and drop it from the data sent to the model\n",
    "customer_ids = demo_df['customerID']\n",
    "labels = demo_df['Churn']\n",
    "X_demo = demo_df.drop(columns=['customerID', 'Churn'])\n",
    "\n",
    "# Convert the DataFrame to a list of lists for prediction\n",
    "input_data = X_demo.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc8ee30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
       "       'tenure', 'PhoneService', 'PaperlessBilling', 'MonthlyCharges',\n",
       "       'TotalCharges', 'Churn', 'AverageMonthlyCharges', 'MultipleLines_No',\n",
       "       'MultipleLines_No phone service', 'MultipleLines_Yes',\n",
       "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
       "       'InternetService_No', 'OnlineSecurity_No',\n",
       "       'OnlineSecurity_No internet service', 'OnlineSecurity_Yes',\n",
       "       'OnlineBackup_No', 'OnlineBackup_No internet service',\n",
       "       'OnlineBackup_Yes', 'DeviceProtection_No',\n",
       "       'DeviceProtection_No internet service', 'DeviceProtection_Yes',\n",
       "       'TechSupport_No', 'TechSupport_No internet service', 'TechSupport_Yes',\n",
       "       'StreamingTV_No', 'StreamingTV_No internet service', 'StreamingTV_Yes',\n",
       "       'StreamingMovies_No', 'StreamingMovies_No internet service',\n",
       "       'StreamingMovies_Yes', 'Contract_Month-to-month', 'Contract_One year',\n",
       "       'Contract_Two year', 'PaymentMethod_Bank transfer (automatic)',\n",
       "       'PaymentMethod_Credit card (automatic)',\n",
       "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check',\n",
       "       'TenureGroups_0-1 year', 'TenureGroups_1-2 years',\n",
       "       'TenureGroups_2-4 years', 'TenureGroups_4-5 years',\n",
       "       'TenureGroups_5+ years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaab947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the JSON payload\n",
    "payload = {\"instances\": input_data}\n",
    "\n",
    "# Serialize and save payload to JSON file\n",
    "json_file_path = 'payload.json'\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(payload, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc35653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://asia-south1-prediction-aiplatform.googleapis.com/]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints predict 3538624242369167360 \\\n",
    "  --region=asia-south1 \\\n",
    "  --json-request=payload.json >> output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef525f",
   "metadata": {},
   "source": [
    "### Post-Prediction Processing\n",
    "- **Interpreting Results:** Predictions obtained from the model are specific scores indicating the likelihood of churn. These scores are converted into binary labels based on a threshold, typically 0.5, distinguishing between 'Churn' and 'Not Churn'.\n",
    "- **Mapping Predictions to Customer IDs:** For practical deployment and review purposes, each prediction is associated back to a customer ID, providing a straightforward reference to actual data.\n",
    "\n",
    "### Results Presentation\n",
    "- **Output Delivery:** The final step involves presenting the predicted results alongside actual labels for each customer. This comparative format is crucial for validating model performance and is essential for operational transparency.\n",
    "\n",
    "This sequential approach to making real-time predictions systematically addresses various stages from data handling to result presentation, ensuring the model deployed in Vertex AI is utilized effectively. Employing Google Cloud's infrastructure facilitates robust scalability and real-time processing capabilities necessary for responsive machine learning applications. Through this documented framework, stakeholders can replicate or modify the prediction process according to specific business requirements or operational contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785073cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID: 6614-YWYSC, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 9546-KDTRB, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 0871-URUWO, Prediction: Churn, Actul: Churn\n",
      "Customer ID: 5151-HQRDG, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 6624-JDRDS, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 3082-VQXNH, Prediction: Churn, Actul: Churn\n",
      "Customer ID: 1309-XGFSN, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 9402-ORRAH, Prediction: Churn, Actul: Churn\n",
      "Customer ID: 8663-UPDGF, Prediction: Not Churn, Actul: Not Churn\n",
      "Customer ID: 0455-ENTCR, Prediction: Not Churn, Actul: Not Churn\n"
     ]
    }
   ],
   "source": [
    "# Load and parse the predictions from the file\n",
    "with open('output.txt', 'r') as file:\n",
    "    predictions = json.load(file)\n",
    "\n",
    "# Apply a threshold of 0.5 to convert predictions to binary labels\n",
    "binary_labels = [1 if float(pred) >= 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Map binary labels to \"Churn\" or \"Not Churn\"\n",
    "churn_labels = ['Churn' if label == 1 else 'Not Churn' for label in binary_labels]\n",
    "\n",
    "# Print results for each customer ID\n",
    "for customer_id, churn_label, label in zip(customer_ids, churn_labels, labels):\n",
    "    print(f'Customer ID: {customer_id}, Prediction: {churn_label}, Actul: {churn_label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951a317",
   "metadata": {},
   "source": [
    "# Generating Personalized Retention Incentives with OpenAI Assistants\n",
    "\n",
    "To enhance customer retention efforts, this process leverages the OpenAI API to generate personalized incentives for customers predicted to churn. The approach combines advanced machine learning predictions with natural language generation capabilities of GPT-4 to produce tailored, concise, and engaging messages that aim to improve customer retention rates.\n",
    "\n",
    "### **Step 1: Assistant Creation**\n",
    "An assistant is created using the OpenAI API, specifically designed as a 'Customer Retention Specialist'. This assistant is programmed with instructions to generate short, single-sentence retention incentives based on detailed customer profiles and churn predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3453d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "  \n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Customer Retention Specialist\",\n",
    "  instructions=\"\"\"You work as a Customer Retention Specialist at a large telecom company. Your responsibility is to generate personalized retention incentives based on churn predictions from your model when customer details are provided. Ensure it is very concise, limited to a maximum of single sentences, and ready to share directly with the customer.\"\"\",\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062ceb3",
   "metadata": {},
   "source": [
    "### **Step 2: Thread Initialization**\n",
    "A thread is initiated to handle interactions with the assistant. This thread acts as a container for the conversation, maintaining context and ensuring that the assistant's responses remain coherent and relevant to the provided customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba508ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df3906",
   "metadata": {},
   "source": [
    "### **Step 3: Descriptive Prompt Generation**\n",
    "For each customer predicted to churn, a descriptive prompt is constructed using their profile data. This prompt includes demographic details, service usage, and payment methods, formatted into a concise description. This ensures that the assistant has all the necessary context to generate a personalized retention message.\n",
    "\n",
    "### **Step 4: Messaging and Interaction**\n",
    "A message containing the customer's profile along with churn predictions is added to the thread. This message serves as the input to the assistant, prompting it to generate a retention incentive.\n",
    "\n",
    "### **Step 5: Execution and Response Handling**\n",
    "The thread is executed to generate a response from the assistant. Once the run completes, the responses are retrieved, and if successful, the assistant’s suggestions for retention incentives are extracted. These suggestions are then ready to be reviewed and potentially communicated to the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49c4c3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Client Details for Customer ID: 0871-URUWO ---\n",
      "\n",
      "Customer ID 0871-URUWO:\\n- Gender: male, Non-senior citizen\\n- Relationship Status: Partnered; No dependents\\n- Service Duration: 13 months; Uses Fiber optic internet service\\n- Current Plan: Month-to-month contract; Paying $102.25 monthly\\n- Billing Method: Credit card (automatic), Opted for paperless billing\n",
      "\n",
      "\n",
      "*** Incentive Plan for Customer ID 0871-URUWO ***\\n\"We value your choice of our premium services and would like to offer you a special 10% discount on your monthly bill, bringing it down to $92.03 for the next 4 months as a token of our appreciation.\"\n",
      "\n",
      "\n",
      "--- Client Details for Customer ID: 3082-VQXNH ---\n",
      "\n",
      "Customer ID 3082-VQXNH:\\n- Gender: male, Non-senior citizen\\n- Relationship Status: Partnered; No dependents\\n- Service Duration: 3 months; Uses DSL internet service\\n- Current Plan: Month-to-month contract; Paying $29.80 monthly\\n- Billing Method: Credit card (automatic), Paper billing\n",
      "\n",
      "\n",
      "*** Incentive Plan for Customer ID 3082-VQXNH ***\\n\"Welcome aboard! To make these early days even better, we're offering a new customer appreciation discount, reducing your DSL service bill to $24.80 for your next 3 months with us.\"\n",
      "\n",
      "\n",
      "--- Client Details for Customer ID: 9402-ORRAH ---\n",
      "\n",
      "Customer ID 9402-ORRAH:\\n- Gender: female, Senior citizen\\n- Relationship Status: Single; No dependents\\n- Service Duration: 15 months; Uses Fiber optic internet service\\n- Current Plan: Month-to-month contract; Paying $91.50 monthly\\n- Billing Method: Electronic check, Opted for paperless billing\n",
      "\n",
      "\n",
      "*** Incentive Plan for Customer ID 9402-ORRAH ***\\n\"To show our appreciation for your choice in our fiber optic service, we're offering a special senior discount that lowers your monthly rate to $85 for the upcoming 4 months.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each Customer ID\n",
    "customer_ids = ['0871-URUWO', '3082-VQXNH', '9402-ORRAH']  # Example customer IDs\n",
    "\n",
    "\n",
    "for customer_id in customer_ids:\n",
    "    # Retrieve the customer row from the original DataFrame\n",
    "    customer_row = df_original[df_original['customerID'] == customer_id].iloc[0]\n",
    "\n",
    "    # Construct a descriptive sentence containing customer details\n",
    "    description = (\n",
    "        f\"Customer ID {customer_row['customerID']}:\\\\n\"\n",
    "        f\"- Gender: {customer_row['gender'].lower()}, \"\n",
    "        f\"{'Senior' if customer_row['SeniorCitizen'] == 1 else 'Non-senior'} citizen\\\\n\"\n",
    "        f\"- Relationship Status: {'Partnered' if customer_row['Partner'] == 'Yes' else 'Single'}; \"\n",
    "        f\"{'Has dependents' if customer_row['Dependents'] == 'Yes' else 'No dependents'}\\\\n\"\n",
    "        f\"- Service Duration: {customer_row['tenure']} months; Uses {customer_row['InternetService']} internet service\\\\n\"\n",
    "        f\"- Current Plan: {customer_row['Contract']} contract; Paying ${customer_row['MonthlyCharges']:.2f} monthly\\\\n\"\n",
    "        f\"- Billing Method: {customer_row['PaymentMethod']}, \"\n",
    "        f\"{'Opted for paperless billing' if customer_row['PaperlessBilling'] == 'Yes' else 'Paper billing'}\"\n",
    "    )\n",
    "\n",
    "    # Log the customer details for clarity\n",
    "    print(f\"--- Client Details for Customer ID: {customer_id} ---\\n\\n{description}\\n\\n\")\n",
    "\n",
    "    # Add the customer message to the thread for generating the incentive\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=description\n",
    "    )\n",
    "\n",
    "    # Generate the incentive response from the assistant\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    # Process and display the incentive plan\n",
    "    if run.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        incentive_plan = json.loads(messages.json())['data'][0]['content'][0]['text']['value']\n",
    "        print(f\"*** Incentive Plan for Customer ID {customer_id} ***\\\\n{incentive_plan}\\n\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to generate incentive for Customer ID {customer_id}, Status: {run.status}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1513b",
   "metadata": {},
   "source": [
    "\n",
    "## Utilization Strategy\n",
    "This integration of GPT-4 with predictive churn models allows for a dynamic and responsive approach to customer retention. By automating the generation of personalized incentives, the system not only scales the retention efforts but also ensures relevancy and personalization that could significantly enhance customer satisfaction and loyalty.\n",
    "\n",
    "The use of AI-driven tools facilitates an innovative approach to customer retention, combining the predictive power of machine learning with the nuanced understanding of human language provided by natural language processing models. This strategy underscores a commitment to leveraging cutting-edge technology to improve business outcomes and customer relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
